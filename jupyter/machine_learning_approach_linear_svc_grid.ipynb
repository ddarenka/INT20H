{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\andreshat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', index_col = 'id')\n",
    "test = pd.read_csv('../data/test.csv', index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def process(text):\n",
    "    res = re.sub('<.*?>', ' ', text)\n",
    "    res = re.sub('\\W', ' ', res)\n",
    "    res = re.sub('\\s+[a-zA-Z]\\s+', ' ', res)\n",
    "    res = re.sub('\\s+', ' ', res)\n",
    "    res = re.sub(r'\\d+', '', res)\n",
    "    word_list = word_tokenize(res)\n",
    "#     word_list = [WordNetLemmatizer().lemmatize(w) for w in word_list]\n",
    "#     word_list = [i for i in word_list if len(i) >= 3]\n",
    "    filtered_res = \" \".join([w for w in word_list if w not in stop_words])\n",
    "    return filtered_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['processed'] = train['review'].apply(lambda x: process(x))\n",
    "test['processed'] = test['review'].apply(lambda x: process(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It Libby talking Desmond flashback anyone confused past like end hospital Hurley know despited Libby dying season character explored season get answers questions surrounding BTW great episode It really great cliffhanger interesting questions like happened Eko Lock four toe statue wait till season Lost rules hope unanswered questions answered loved explained plane actually crashed Desmond manage type numbers time'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['processed'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df = 2, max_df = 0.99, ngram_range = (1, 3))\n",
    "x_train_vector = tfidf.fit_transform(train['processed'])\n",
    "y_train = train['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LinearSVC(), n_jobs=-1,\n",
       "             param_grid={'C': [0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93,\n",
       "                               0.94]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'C': [0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94]}\n",
    "#           'multi_class': ['ovr', 'crammer_singer'],\n",
    "#           'loss': ['hinge', 'squared_hinge']}\n",
    "gs = GridSearchCV(LinearSVC(), params, scoring = 'f1', n_jobs = -1)\n",
    "gs.fit(x_train_vector, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_vector = tfidf.transform(test['processed'])\n",
    "test_pred = gs.best_estimator_.predict(x_test_vector)\n",
    "\n",
    "sub = pd.read_csv('../data/submission.csv')\n",
    "sub['sentiment'] = test_pred\n",
    "# sub.to_csv('./my_sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9097535008469129"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.91}"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission_linear_svm_gs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
